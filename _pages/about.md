---
permalink: /
title: "Jingjie Zhang"
excerpt: "Ph.D. Candidate in Computer Science | Research in Computational Biology and Machine Learning"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About Me
I am a Ph.D. candidate at [**The Chinese University of Hong Kong (CUHK)**](https://www.cuhk.edu.hk/english/index.html), starting in 2024. My research focuses on Artificial intelligence (AI) for drug design. I am particularly interested in AI for Post-translational modification (PTM). Previously, I completed my undergraduate studies at [Shandong University (SDU)](https://www.sdu.edu.cn/index.htm), where I developed a strong foundation in computer science and bioinformatics.

## Education
- **Ph.D. in Department of Computer Science and Engineering**, The Chinese University of Hong Kong (CUHK), 2024‚Äì2028 (Expected)
- **B.Sc. in College of Software Engineering**, Shandong University (SDU), 2020‚Äì2024

## Research
### SAGEPhos: SAGE Bio-Coupled and Augmented Fusion for Phosphorylation Site Detection
<span style="color: purple;">Jingjie Zhang</span>, Hanqun Cao, Zijun Gao, Xiaorui Wang, Chunbin Gu
- **Description**: SAGEPhos is a structure-aware framework for phosphorylation site prediction that modifies protein inputs using auxiliary modalities at two levels (Bio-Coupled and Bio-Augmented fusion).
- <span style="color: red;">Note: This paper has been accepted at [ICLR 2025](https://openreview.net/forum?id=hLwcNSFhC2).</span>
- **Paper**: [arxiv](https://arxiv.org/abs/2502.07384)
- **Code**: [GitHub Repository](https://github.com/ZhangJJ26/SAGEPhos)

### Retrosynthesis prediction with an interpretable deep-learning framework based on molecular assembly tasks
Yu Wang, Chao Pang, Yuzhe Wang, Junru Jin, <span style="color: purple;">Jingjie Zhang</span>, Xiangxiang Zeng, Ran Su, Quan Zou & Leyi Wei
- **Description**: RetroExplainer is a novel deep learning-based approach that formulates retrosynthesis as a molecular assembly process, utilizing a multi-sense graph transformer, structure-aware contrastive learning, and dynamic multi-task learning to achieve state-of-the-art performance across 12 benchmark datasets with enhanced interpretability.
- <span style="color: red;">Note: This paper has been accepted at [Nature Communications](https://www.nature.com/articles/s41467-023-41698-5).</span>
- **Code**: [GitHub Repository](https://github.com/wangyu-sd/RetroExplainer)

### MolCAP: Molecular Chemical reActivity Pretraining and prompted-finetuning enhanced molecular representation learning
Yu Wang, <span style="color: purple;">Jingjie Zhang</span>, Junru Jin, Leyi Wei
- **Description**: MolCAP is a graph-pretraining Transformer leveraging chemical reactivity knowledge and prompted fine-tuning, outperforming traditional molecular pretraining frameworks across 13 biomedical datasets.
- Note: This paper has been accepted at [Computers in Biology and Medicine](https://www.sciencedirect.com/science/article/abs/pii/S0010482523011319).
- **Code**: [GitHub Repository](https://github.com/wangyu-sd/MolCAP)

## Honors
- üèÜ **Shandong University President's Award (Â±±‰∏úÂ§ßÂ≠¶2023Âπ¥Â∫¶Ê†°ÈïøÂ•ñ)** (Dec 2023)
- üèÖ **National Scholarship** (Oct 2022, Oct 2021)

## Contact
- **Email**: [1155224008@link.cuhk.edu.hk](mailto:1155224008@link.cuhk.edu.hk)

